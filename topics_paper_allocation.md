# 2025 Fall COMP6211J Topics Allocation

# Category 1.  Architecture and Network for LLM

### Topic 1. AI Chip Design.

- Group 1-1
    - Member: Hongyi Wang and Xiangfeng Sun:
    - Paper: Meta's Second Generation AI Chip: Model-Chip Co-Design and Productionization Experiences
    - Slot: Session 1-1 (2025/10/21)
- Group 1-2
    - Member: LI Pengbo and Song Linkai
    - Paper: The Sparsity-Aware LazyGPU Architecture
    - Slot: Session 1-2 (2025/10/21)

### Topic 2. Heterogeneous Hardware for LLM Services.

- Group 2-1
    - Member: Shiyi Liu and Yiran Xia
    - Paper: H2-LLM: Hardware-Dataflow Co-Exploration for Heterogeneous Hybrid-Bonding-based Low-Batch LLM Inference
    - Slot: Session 1-3 (2025/10/21)
- Group 2-2
    - Member: Yuwei Wu and Longge Deng
    - Paper: LIA: A Single-GPU LLM Inference Acceleration with Cooperative AMX-Enabled CPU-GPU Computation and CXL Offloading
    - Slot: Session 1-4 (2025/10/21)

### Topic 3.  Communication Optimizations in LLM Serving.

- Group 3-1
    - Member: Zihao Wang and Zhaoxiang Bao
    - Paper: MCCS: A Service-based Approach to Collective Communication for Multi-Tenant Cloud
    - Slot: Session 2-1 (2025/10/23)
- Group 3-2
    - Member: Yichen Liu and Jichen Zhang
    - Paper: Rdma over ethernet for distributed training at meta scale
    - Slot: Session 2-2 (2025/10/23)

# Category 2. LLM Training Inference and RL Systems

### Topic 4. Long Context LLM Training.

- Group 4-1
    - Member: Wong Hiu Tung and Ma Sum Yi
    - Paper: DISTFLASHATTN: Distributed Memory-efficient Attention for Long-context LLMs Training
    - Slot: Session 2-3 (2025/10/23)
- Group 4-2
    - Member: Dakai An and Tianyu Feng
    - Paper: ByteScale: Communication-Efficient Scaling of LLM Training with a 2048K Context Length on 16384 GPUs
    - Slot: Session 2-4 (2025/10/23)

### Topic 5. Mixture of Expert Training.

- Group 5-1
    - Member: Zhenghong Huang and Wenxi Qiu
    - Paper: Comet: Fine-grained computation-communication overlapping for mixture-of-experts
    - Slot: Session 3-1 (2025/10/28)
- Group 5-2
    - Member: Wenkai Li and Mengming Li
    - Paper: Hetermoe: Efficient training of mixture-of-experts models on heterogeneous gpus
    - Slot: Session 3-2 (2025/10/28)

### Topic 6.  Prefill-Decoding Disaggregated Inference.

- Group 6-1
    - Member: Bu Jin and Yu Liu
    - Paper: Mooncake: Trading more storage for less computationâ€”a KVCache-centric architecture for serving LLM chatbot
    - Slot: Session 3-3 (2025/10/28)
- Group 6-2
    - Member: Heyang Sun and Xu Xu
    - Paper: Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference
    - Slot: Session 3-4 (2025/10/28)

### Topic 7. Attention-Fully Connected Layer Disaggregated Inference.

- Group 7-1
    - Member: Songrun Xie
    - Paper: MegaScale-Infer: Efficient Mixture-of-Experts Model Serving with Disaggregated Expert Parallelism
    - Slot: Session 4-1 (2025/10/30)

### Topic 8. RL Systems.

- Group 8-1
    - Member: Yuguang Zhou and Jiazhi Mi
    - Paper: Hybridflow: A flexible and efficient rlhf framework
    - Slot: Session 4-2 (2025/10/30)
- Group 8-2
    - Member: Ding Pan and Jiayi Cheng
    - Paper: AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning
    - Slot: Session 4-3 (2025/10/30)

# Category 3. Algorithmic Advances for LLM

### Topic 9. Diffusion Language Model.

- Group 9-1
    - Member: Shiyuan Song and Junjie Hou
    - Paper: Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution
    - Slot: Session 4-4 (2025/10/30)
- Group 9-2
    - Member: Chaolei Tan and Ziqi Jiang
    - Paper: Large language diffusion models
    - Slot: Session 5-1 (2025/11/04)

### Topic 10. LLM Inference Acceleration Algorithms.

- Group 10-1
    - Member: Caieus Moreign and Chenyu Liu
    - Paper: H2o: Heavy-hitter oracle for efficient generative inference of large language models
    - Slot: Session 5-2 (2025/11/04)
- Group 10-2
    - Member: Haodong Wang and Qianli Liu
    - Paper: LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding
    - Slot: Session 5-3 (2025/11/04)
- Group 10-3
    - Member: Jiangnan Yu and Zhenxiao Cao
    - Paper: Native sparse attention: Hardware-aligned and natively trainable sparse attention
    - Slot: Session 5-4 (2025/11/04)

### Topic 11. Efficient SFT Algorithms.

- Group 11-1
    - Member: Yejia Liu and Haoxian Liu
    - Paper: GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection
    - Slot: Session 6-1 (2025/11/06)
- Group 11-2
    - Member: Vinayak Khurana and Eman Ansar
    - Paper: Flora: Low-Rank Adapters Are Secretly Gradient Compressors
    - Slot: Session 6-2 (2025/11/06)

### Topic 12. RL Algorithms for LLM reasoning.

- Group 12-1
    - Member: Runze Zhang and Mingyang Zhao
    - Paper: Proximal policy optimization algorithms
    - Slot: Session 6-3 (2025/11/06)
- Group 12-2
    - Member: Haochen Shi and Baixuan Xu
    - Paper: Deepseekmath: Pushing the limits of mathematical reasoning in open language models
    - Slot: Session 6-4 (2025/11/06)
- Group 12-3
    - Member: Zibin Meng and Pengfei Wu
    - Paper: Group sequence policy optimization
    - Slot: Session 7-1 (2025/11/11)

# Category 4. MultiModal Foundation Model

### Topic 13. Multimodal Information Modeling and Reasoning.

- Group 13-1
    - Member: Pusen Gao and Yiyao Peng
    - Paper: Qwen2. 5-vl technical report
    - Slot: Session 7-2 (2025/11/11)
- Group 13-2
    - Member: Tse Wai Chung and Tuan An To
    - Paper: Mmada: Multimodal large diffusion language models
    - Slot: Session 7-3 (2025/11/11)
- Group 13-3
    - Member: Tianci Yin and  Yu Foon Darin Chau
    - Paper: RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models
    - Slot: Session 7-4 (2025/11/11)
- Group 13-4
    - Member: Yubo Zhao and Dongjie Yang
    - Paper: Qwen2.5-Omni Technical Report
    - Slot: Session 8-1 (2025/11/13)

### Topic 14. Image- Video- Generation and Acceleration.

- Group 14-1
    - Member: Zhizhou Zhong and Zhenyuan Zhang
    - Paper: CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer
    - Slot: Session 8-2 (2025/11/13)
- Group 14-2
    - Member: Gongye Liu and Zixuan Ye
    - Paper: Seedance 1.0: Exploring the Boundaries of Video Generation Models
    - Slot: Session 8-3 (2025/11/13)
- Group 14-3
    - Member: Meng Chu and Mingzhe Zheng
    - Paper: Radial Attention: $ O (n$\backslash$log n) $ Sparse Attention with Energy Decay for Long Video Generation
    - Slot: Session 8-4 (2025/11/13)
- Group 14-4
    - Member: Jianxin Huang and Chenran Huang
    - Paper: Sparse VideoGen2: Accelerate Video Generation with Sparse Attention via Semantic-Aware Permutation
    - Slot: Session 9-1 (2025/11/18)
- Group 14-5
    - Member: Hanlin Wang and Xuanhua He
    - Paper: SpargeAttention: Accurate and Training-free Sparse Attention Accelerating Any Model Inference
    - Slot: Session 9-2 (2025/11/18)

# Category 5.  LLM Agent, Evaluation and Applications

### Topic 15. LLM for Coding.

- Group 15-1
    - Member: Zhantong Xue and Le Xu
    - Paper: Deepseek-coder-v2: Breaking the barrier of closed-source models in code intelligence
    - Slot: Session 9-3 (2025/11/18)
- Group 15-2
    - Member: Danxuan Liang and Yu Kei Jian
    - Paper: Qwen2. 5-xCoder: Multi-Agent Collaboration for Multilingual Code Instruction Tuning
    - Slot: Session 9-4 (2025/11/18)

### Topic 16. LLM for Math.

- Group 16-1
    - Member: Zhaochen Su and Junteng Liu
    - Paper: Deepseek-prover-v2: Advancing formal mathematical reasoning via reinforcement learning for subgoal decomposition
    - Slot: Session 10-1 (2025/11/20)

### Topic 17. GUI Agent.

- Group 17-1
    - Member: Yuxuan Cao and Junlong Li
    - Paper: AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials
    - Slot: Session 10-2 (2025/11/20)
- Group 17-2
    - Member: Shijue Huang and Changxuan Fan
    - Paper: Opencua: Open foundations for computer-use agents
    - Slot: Session 10-3 (2025/11/20)

### Topic 18. Retrieval Augmented Generation.

- Group 18-1
    - Member: Bowen Liu and Siqi Wang
    - Paper: Chameleon: A Heterogeneous and Disaggregated Accelerator System for Retrieval-Augmented Language Models
    - Slot: Session 10-4 (2025/11/20)
- Group 18-2
    - Member: Chunyin Li and Junle Chen
    - Paper: ReasonIR: Training Retrievers for Reasoning Tasks
    - Slot: Session 11-1 (2025/11/25)
- Group 18-3
    - Member: Xiaoyu Han and Kwok Tsun On
    - Paper: Search-r1: Training llms to reason and leverage search engines with reinforcement learning
    - Slot: Session 11-2 (2025/11/25)

### Topic 19. LLM Evaluation and Benchmarks.

- Group 19-1
    - Member: Ling Liang and Xinyu Geng
    - Paper: The Berkeley Function Calling Leaderboard (BFCL): From Tool Use to Agentic Evaluation of Large Language Models
    - Slot: Session 11-3 (2025/11/25)
- Group 19-2
    - Member: Yuwei Wu and Longge Deng
    - Paper: DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis
    - Slot: Session 11-4 (2025/11/25)